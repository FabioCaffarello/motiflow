services:
  minio:
    restart: always
    image: minio/minio
    platform: linux/amd64
    container_name: minio_s3
    ports:
      - "9000:9000"
      - "9001:9001"
    command: server /data --console-address ":9001" --address ":9000"
    environment:
      MINIO_ROOT_USER: ${MINIO_USERNAME}
      MINIO_ROOT_PASSWORD: ${MINIO_PASSWORD}
    volumes:
      - minio-data:/data
    networks:
      - motiflow-network
  mc:
    image: minio/mc
    platform: linux/amd64
    depends_on:
      - minio
    container_name: mc
    env_file:
      - .env
    entrypoint: >
      /bin/sh -c " /tmp/wait-for-it.sh minio:9000 && /usr/bin/mc alias set minio http://minio:9000 ${AWS_ACCESS_KEY_ID} ${AWS_SECRET_ACCESS_KEY} && /usr/bin/mc mb minio/motiflow; exit 0; "
    volumes:
      - ./scripts/wait-for-it.sh:/tmp/wait-for-it.sh
    networks:
      - motiflow-network

  spark-connect:
    build:
      context: ./images/spark
      dockerfile: Dockerfile
    container_name: spark-connect
    command:
      - /opt/spark/sbin/start-connect-server.sh
      - --packages
      - org.apache.spark:spark-sql-kafka-0-10_2.13:4.0.1,org.apache.hadoop:hadoop-aws:3.3.6,com.amazonaws:aws-java-sdk-bundle:1.12.262,com.mysql:mysql-connector-j:8.0.33
      - --conf
      - spark.hadoop.fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider
      - --conf
      - spark.hadoop.fs.s3a.access.key=${MINIO_ACCESS_KEY}
      - --conf
      - spark.hadoop.fs.s3a.secret.key=${MINIO_SECRET_KEY}
    environment:
      - SPARK_NO_DAEMONIZE=true
    ports:
      - "15002:15002"
      - "4040-4045:4040-4045"
    volumes:
      - spark-warehouse:/opt/spark/warehouse
      - spark-checkpoints:/tmp/spark-checkpoints
    depends_on:
      - minio
    networks:
      - motiflow-network

volumes:
  minio-data:
  spark-warehouse:
  spark-checkpoints:
  conf:

networks:
  motiflow-network:
    name: motiflow-network
    driver: bridge
